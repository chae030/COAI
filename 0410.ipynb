{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.05578825]] , W.shape =  (1, 1) , b =  [0.33450656] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1)\n",
    "t_data = np.array([2, 3 ,4, 5, 6]).reshape(5, 1)\n",
    "\n",
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func (x, t) :\n",
    "    y = np.dot(x, W) + b\n",
    "    return (np.sum((t - y) ** 2)) / (len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative (f, x) :\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished :\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val (x, t) :\n",
    "    y = np.dot (x, W) + b\n",
    "    return (np.sum((t - y) ** 2)) / (len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (x) :\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  14.019976114643327 Initial W =  [[0.05578825]] \n",
      " , b =  [0.33450656]\n",
      "step =  0 error value =  8.260686702354793 W =  [[0.30344444]] , b =  [0.38960976]\n",
      "step =  400 error value =  0.0021864660758544826 W =  [[1.03036464]] , b =  [0.89040085]\n",
      "step =  800 error value =  0.00013950946196755658 W =  [[1.00767006]] , b =  [0.97231544]\n",
      "step =  1200 error value =  8.901528449677733e-06 W =  [[1.00193744]] , b =  [0.99300693]\n",
      "step =  1600 error value =  5.679701406834187e-07 W =  [[1.00048939]] , b =  [0.99823356]\n",
      "step =  2000 error value =  3.6239852799574636e-08 W =  [[1.00012362]] , b =  [0.9995538]\n",
      "step =  2400 error value =  2.312316857652651e-09 W =  [[1.00003123]] , b =  [0.99988729]\n",
      "step =  2800 error value =  1.4753948587102048e-10 W =  [[1.00000789]] , b =  [0.99997153]\n",
      "step =  3200 error value =  9.41389145138191e-12 W =  [[1.00000199]] , b =  [0.99999281]\n",
      "step =  3600 error value =  6.006619296880722e-13 W =  [[1.0000005]] , b =  [0.99999818]\n",
      "step =  4000 error value =  3.8325782254641954e-14 W =  [[1.00000013]] , b =  [0.99999954]\n",
      "step =  4400 error value =  2.445411511498837e-15 W =  [[1.00000003]] , b =  [0.99999988]\n",
      "step =  4800 error value =  1.560317113726275e-16 W =  [[1.00000001]] , b =  [0.99999997]\n",
      "step =  5200 error value =  9.955743854298895e-18 W =  [[1.]] , b =  [0.99999999]\n",
      "step =  5600 error value =  6.3523580400682415e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  4.0531902276068366e-20 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  2.5861574111271377e-21 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  1.6500850354572483e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  1.0531729137426629e-23 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  6.731993124496262e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  4.319112063698192e-26 W =  [[1.]] , b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(8001) :\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0) :\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.loadtxt('./data-01.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[:, 0:-1]\n",
    "t_data = loaded_data[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.23289079]\n",
      " [0.14041657]\n",
      " [0.97872163]] , W.shape =  (3, 1) , b =  [0.60769017] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  2790.2628141032283 Initial W =  [[0.23289079]\n",
      " [0.14041657]\n",
      " [0.97872163]] \n",
      " , b =  [0.60769017]\n",
      "step =  0 error value =  1036.1059399027345 W =  [[0.31717112]\n",
      " [0.22524861]\n",
      " [1.0654208 ]] , b =  [0.60832317]\n",
      "step =  400 error value =  6.819111776742344 W =  [[0.43969648]\n",
      " [0.38119907]\n",
      " [1.18414719]] , b =  [0.60846691]\n",
      "step =  800 error value =  6.6540750415117165 W =  [[0.43214154]\n",
      " [0.40199954]\n",
      " [1.17117309]] , b =  [0.60764193]\n",
      "step =  1200 error value =  6.535193299175608 W =  [[0.4252389 ]\n",
      " [0.41971803]\n",
      " [1.1605766 ]] , b =  [0.60683054]\n",
      "step =  1600 error value =  6.449231412665689 W =  [[0.41893733]\n",
      " [0.43482751]\n",
      " [1.15194537]] , b =  [0.60603023]\n",
      "step =  2000 error value =  6.386810673433047 W =  [[0.41318869]\n",
      " [0.44772669]\n",
      " [1.1449366 ]] , b =  [0.60523893]\n",
      "step =  2400 error value =  6.34127354957907 W =  [[0.40794796]\n",
      " [0.45875179]\n",
      " [1.13926547]] , b =  [0.60445492]\n",
      "step =  2800 error value =  6.307884782419611 W =  [[0.40317316]\n",
      " [0.46818655]\n",
      " [1.13469556]] , b =  [0.60367681]\n",
      "step =  3200 error value =  6.283268782525322 W =  [[0.39882528]\n",
      " [0.47627052]\n",
      " [1.13103068]] , b =  [0.60290345]\n",
      "step =  3600 error value =  6.265013109106439 W =  [[0.39486815]\n",
      " [0.48320608]\n",
      " [1.12810823]] , b =  [0.60213388]\n",
      "step =  4000 error value =  6.251388740579354 W =  [[0.39126832]\n",
      " [0.48916433]\n",
      " [1.12579354]] , b =  [0.60136735]\n",
      "step =  4400 error value =  6.241152522078006 W =  [[0.38799492]\n",
      " [0.49429002]\n",
      " [1.12397516]] , b =  [0.6006032]\n",
      "step =  4800 error value =  6.233407474048457 W =  [[0.3850195 ]\n",
      " [0.49870568]\n",
      " [1.12256102]] , b =  [0.59984094]\n",
      "step =  5200 error value =  6.227503873254793 W =  [[0.38231589]\n",
      " [0.50251512]\n",
      " [1.12147509]] , b =  [0.59908015]\n",
      "step =  5600 error value =  6.222969090733532 W =  [[0.37986007]\n",
      " [0.50580639]\n",
      " [1.1206547 ]] , b =  [0.59832049]\n",
      "step =  6000 error value =  6.219457733514202 W =  [[0.37762999]\n",
      " [0.50865418]\n",
      " [1.12004827]] , b =  [0.59756169]\n",
      "step =  6400 error value =  6.2167161391428305 W =  [[0.37560547]\n",
      " [0.51112198]\n",
      " [1.1196134 ]] , b =  [0.59680354]\n",
      "step =  6800 error value =  6.214557030379081 W =  [[0.37376801]\n",
      " [0.51326372]\n",
      " [1.11931534]] , b =  [0.59604586]\n",
      "step =  7200 error value =  6.212841373620878 W =  [[0.37210073]\n",
      " [0.51512535]\n",
      " [1.11912564]] , b =  [0.59528851]\n",
      "step =  7600 error value =  6.211465354180924 W =  [[0.37058818]\n",
      " [0.51674597]\n",
      " [1.11902105]] , b =  [0.5945314]\n",
      "step =  8000 error value =  6.210350993613722 W =  [[0.36921628]\n",
      " [0.51815898]\n",
      " [1.11898267]] , b =  [0.59377444]\n",
      "step =  8400 error value =  6.209439365439273 W =  [[0.36797216]\n",
      " [0.51939285]\n",
      " [1.11899513]] , b =  [0.59301756]\n",
      "step =  8800 error value =  6.208685669570786 W =  [[0.36684413]\n",
      " [0.52047195]\n",
      " [1.11904603]] , b =  [0.59226073]\n",
      "step =  9200 error value =  6.208055640261258 W =  [[0.3658215 ]\n",
      " [0.52141712]\n",
      " [1.11912537]] , b =  [0.5915039]\n",
      "step =  9600 error value =  6.207522913934603 W =  [[0.36489455]\n",
      " [0.52224625]\n",
      " [1.11922512]] , b =  [0.59074704]\n",
      "step =  10000 error value =  6.207067090479715 W =  [[0.36405445]\n",
      " [0.52297465]\n",
      " [1.11933889]] , b =  [0.58999016]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(10001) :\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0) :\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.91340078])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'logistic_regression' has no attribute 'error_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-2\u001b[39m\n\u001b[1;32m     12\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : loss_func(x_data, t_data)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial error value = \u001b[39m\u001b[38;5;124m\"\u001b[39m, lr\u001b[38;5;241m.\u001b[39merror_val(x_data, t_data), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial W = \u001b[39m\u001b[38;5;124m\"\u001b[39m, W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, b = \u001b[39m\u001b[38;5;124m\"\u001b[39m, b)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10001\u001b[39m) :\n\u001b[1;32m     17\u001b[0m     W \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m lr\u001b[38;5;241m.\u001b[39mnumerical_derivative(f, W)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'logistic_regression' has no attribute 'error_val'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logistic_regression as lr\n",
    "\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n",
    "t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10, 1)\n",
    "\n",
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", lr.error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(10001) :\n",
    "    W -= learning_rate * lr.numerical_derivative(f, W)\n",
    "    b -= learning_rate * lr.numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0) :\n",
    "        print(\"step = \", step, \"error value = \", lr.error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
